{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOMS Paper NANOG (5.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using Glob\n",
    "using HMMBase\n",
    "using JSON\n",
    "using ParsimoniousMonitoring: LogEntry\n",
    "using PyPlot\n",
    "using Statistics\n",
    "using ThesisTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_log(d::Dict) = LogEntry(map(x -> d[string(x)], fieldnames(LogEntry))...)\n",
    "\n",
    "function load_results(filename)\n",
    "    obj = JSON.parsefile(filename)\n",
    "    Dict(k => map(parse_log, v) for (k, v) in obj)\n",
    "end\n",
    "\n",
    "# TODO: Move to dedicated file\n",
    "read_ts(filename) = CSV.read(filename, header = [\"timestep\", \"rtt\"])\n",
    "\n",
    "function load_scenario(path; return_names = false)\n",
    "    files = map(x -> splitext(x)[1], glob(\"*.csv\", path))\n",
    "    models = []\n",
    "    series = []\n",
    "    names = []\n",
    "    for file in files\n",
    "        push!(models, read_model(\"$file.json\"))\n",
    "        push!(series, read_ts(\"$file.csv\"))\n",
    "        push!(names, basename(file))\n",
    "    end\n",
    "    data = hcat(map(x -> x.rtt, series)...)\n",
    "    name = splitpath(path)[end]\n",
    "    if return_names\n",
    "        return name, names, models, data\n",
    "    end\n",
    "    name, models, data\n",
    "end\n",
    "\n",
    "function read_model(filename)\n",
    "    obj = JSON.parsefile(filename)\n",
    "    A = permutedims(hcat(obj[\"transmat\"]...))\n",
    "    B = map(obj[\"states\"]) do (_, d)\n",
    "        components = map(zip(d[\"means\"], d[\"variances\"])) do (μ, σ2)\n",
    "            Normal(μ, sqrt(σ2))\n",
    "        end\n",
    "        MixtureModel(components, [d[\"weights\"]...])\n",
    "    end\n",
    "    HMM(A, B)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Validation against real latency data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\n",
    "    \"../data/noms_scenarios/Haifa_Santiago/\",\n",
    "    \"../data/noms_scenarios/Paris_Santiago/\",\n",
    "    \"../data/noms_scenarios/Paris_Tokyo/\",\n",
    "    \"../data/noms_scenarios/Singapore_HongKong/\"\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "τmax = 100\n",
    "for file in scenarios\n",
    "    models = load_scenario(file)[2]\n",
    "    @show file\n",
    "    @show prod(m -> size(m, 1) * τmax, models)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"../results/Haifa_Santiago.json\",\n",
    "    \"../results/Paris_Santiago.json\",\n",
    "    \"../results/Paris_Tokyo.json\",\n",
    "    \"../results/Singapore_HongKong.json\"\n",
    "]\n",
    "\n",
    "function min_delay_gap(log)\n",
    "    delay = sum(skipmissing(map(x -> isnothing(x.delay) ? missing : x.delay, log)))\n",
    "    delay_opt = sum(skipmissing(map(x -> isnothing(x.delay_opt) ? missing : x.delay_opt, log)))\n",
    "    (delay - delay_opt) / delay_opt\n",
    "end\n",
    "\n",
    "metrics = Dict(\n",
    "    \"processing_time\" => log -> mean(x -> x.time, log),\n",
    "    \"avg_measures\" => log -> mean(x -> sum(x.a), log),\n",
    "    \"min_delay_reached\" => log -> mean(x -> x.delay == x.delay_opt, log) * 100,\n",
    "    \"min_delay_gap\" => log -> min_delay_gap(log) * 100\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame([String[], String[], String[], Real[]], [:scenario, :policy, :metric, :value])\n",
    "for file in files\n",
    "    scenario = splitext(basename(file))[1]\n",
    "    results = load_results(file)\n",
    "    for (policy, log) in results, (metric, f) in metrics\n",
    "        push!(df, (scenario, policy, metric, f(log)))\n",
    "    end\n",
    "end\n",
    "df = unstack(df, :metric, :value);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.scenario .== \"Singapore_HongKong\",:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure Singapore - HK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, names, models, data = load_scenario(\"../data/noms_scenarios/Singapore_HongKong/\", return_names = true)\n",
    "results = load_results(\"../results/Singapore_HongKong.json\")\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = subplots()\n",
    "ax.plot(coalesce.(data[:,1], NaN), label = \"Direct\")\n",
    "ax.plot(coalesce.(data[:,2], NaN), label = \"via Narita\")\n",
    "ax.plot(coalesce.(data[:,3], NaN), label = \"via Tokyo\")\n",
    "ax.scatter(1:size(data, 1), map(x -> coalesce(x.delay, NaN), results[\"Heuristic\"]), c = \"black\", s = 10)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure Haifa - Santiago**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, names, models, data = load_scenario(\"../data/noms_scenarios/Haifa_Santiago/\", return_names = true)\n",
    "results = load_results(\"../results/Haifa_Santiago.json\")\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pywith plt.style.context(\"classicthesis\") begin\n",
    "    fig, ax = subplots(figsize = (4.6, 4.6*0.45))\n",
    "    ax.plot(coalesce.(data[:,1], NaN), label = \"Direct\")\n",
    "    ax.plot(coalesce.(data[:,2], NaN), label = \"via Boston\")\n",
    "    ax.plot(coalesce.(data[:,3], NaN), label = \"via Curitiba\")\n",
    "    ax.plot(coalesce.(data[:,4], NaN), label = \"via Dublin\")\n",
    "    ax.scatter(1:size(data, 1), map(x -> coalesce(x.delay, NaN), results[\"RH-3\"]), c = \"black\", s = 10)\n",
    "    ax.set(xlabel = \"Temps\", ylabel = \"RTT (ms)\")\n",
    "    ax.legend(loc = \"upper left\", ncol = 2)\n",
    "    fig.savefig(\"../figures/haifa_santiago_rh3.pdf\")\n",
    "    # save_thesis(\"haifa_santiago_rh3\", clean = true, hwr = 0.35)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = subplots(figsize = (10, 9), nrows = 3, sharex = true)\n",
    "axs[1].plot(data[:,1], label = \"Déterministe\")\n",
    "axs[1].plot(data[:,2], label = \"Stochastique\")\n",
    "axs[1].scatter(instants, data[instants,2], ec = colorblindmap[3], fc = \"none\", marker = \"o\", label = \"Mesure\")\n",
    "axs[1].set(ylabel = L\"$L(t)$\", ylim = (4, 12))\n",
    "axs[1].legend(loc = \"upper left\", ncol = 3)\n",
    "\n",
    "axs[2].plot(predictor)\n",
    "# Bug with axhline and tikzplotlib\n",
    "# axs[2].axhline(xmin, c = \"black\", ls = \"--\", lw = 1.0, label = \"xmin\")\n",
    "# axs[2].axhline(xmax, c = \"black\", ls = \"--\", lw = 1.0, label = \"xmax\")\n",
    "axs[2].plot([0, size(data, 1)], [xmin, xmin], c = \"black\", ls = \"--\", lw = 1.0, label = \"xmin, xmax\")\n",
    "axs[2].plot([0, size(data, 1)], [xmax, xmax], c = \"black\", ls = \"--\", lw = 1.0)\n",
    "axs[2].set(ylabel = L\"\\gamma_{t-1,t}(1)\", ylim = (0, 1.0))\n",
    "axs[2].legend(loc = \"upper left\", ncol = 2)\n",
    "\n",
    "axs[3].plot(cumsum(penalized_gain(mdp, logbook_never)), label = \"Jamais\")\n",
    "axs[3].plot(cumsum(penalized_gain(mdp, logbook_always)), label = \"Toujours\")\n",
    "axs[3].plot(cumsum(penalized_gain(mdp, logbook_greedy)), label = \"Glouton\")\n",
    "axs[3].plot(cumsum(penalized_gain(mdp, logbook_mdp_99)), label = \"MDP 0.99\")\n",
    "axs[3].set(xlabel = \"Temps\", ylabel = \"Gain pénalisé cumulé\", ylim = (-500, 6000))\n",
    "axs[3].legend(loc = \"upper left\", ncol = 2)\n",
    "axs[3].grid()\n",
    "\n",
    "save_thesis(\"monitoring_1p_greedy_aio\", clean = true, hwr = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
