{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOMS Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using Glob\n",
    "using HMMBase\n",
    "using JSON\n",
    "using ParsimoniousMonitoring: LogEntry\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_log(d::Dict) = LogEntry(map(x -> d[string(x)], fieldnames(LogEntry))...)\n",
    "\n",
    "function load_results(filename)\n",
    "    obj = JSON.parsefile(filename)\n",
    "    Dict(k => map(parse_log, v) for (k, v) in obj)\n",
    "end\n",
    "\n",
    "# TODO: Move to dedicated file\n",
    "read_ts(filename) = CSV.read(filename, header = [\"timestep\", \"rtt\"])\n",
    "\n",
    "function load_scenario(path)\n",
    "    files = map(x -> splitext(x)[1], glob(\"*.csv\", path))\n",
    "    models = []\n",
    "    series = []\n",
    "    for file in files\n",
    "        push!(models, read_model(\"$file.json\"))\n",
    "        push!(series, read_ts(\"$file.csv\"))\n",
    "    end\n",
    "    data = hcat(map(x -> x.rtt, series)...)\n",
    "    name = splitpath(path)[end]\n",
    "    name, models, data\n",
    "end\n",
    "\n",
    "function read_model(filename)\n",
    "    obj = JSON.parsefile(filename)\n",
    "    A = permutedims(hcat(obj[\"transmat\"]...))\n",
    "    B = map(obj[\"states\"]) do (_, d)\n",
    "        components = map(zip(d[\"means\"], d[\"variances\"])) do (μ, σ2)\n",
    "            Normal(μ, sqrt(σ2))\n",
    "        end\n",
    "        MixtureModel(components, [d[\"weights\"]...])\n",
    "    end\n",
    "    HMM(A, B)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Validation against real latency data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\n",
    "    \"../data/noms_scenarios/Haifa_Santiago/\",\n",
    "    \"../data/noms_scenarios/Paris_Santiago/\",\n",
    "    \"../data/noms_scenarios/Paris_Tokyo/\",\n",
    "    \"../data/noms_scenarios/Singapore_HongKong/\"\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "τmax = 100\n",
    "for file in scenarios\n",
    "    models = load_scenario(file)[2]\n",
    "    @show file\n",
    "    @show prod(m -> size(m, 1) * τmax, models)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "168000000 / 10^6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"../results/Haifa_Santiago.json\",\n",
    "    \"../results/Paris_Santiago.json\",\n",
    "    \"../results/Paris_Tokyo.json\",\n",
    "    \"../results/Singapore_HongKong.json\"\n",
    "]\n",
    "\n",
    "function min_delay_gap(log)\n",
    "    delay = sum(skipmissing(map(x -> isnothing(x.delay) ? missing : x.delay, log)))\n",
    "    delay_opt = sum(skipmissing(map(x -> isnothing(x.delay_opt) ? missing : x.delay_opt, log)))\n",
    "    (delay - delay_opt) / delay_opt\n",
    "end\n",
    "\n",
    "metrics = Dict(\n",
    "    \"processing_time\" => log -> mean(x -> x.time, log),\n",
    "    \"avg_measures\" => log -> mean(x -> sum(x.a), log),\n",
    "    \"min_delay_reached\" => log -> mean(x -> x.delay == x.delay_opt, log) * 100,\n",
    "    \"min_delay_gap\" => log -> min_delay_gap(log) * 100\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame([String[], String[], String[], Real[]], [:scenario, :policy, :metric, :value])\n",
    "for file in files\n",
    "    scenario = splitext(basename(file))[1]\n",
    "    results = load_results(file)\n",
    "    for (policy, log) in results, (metric, f) in metrics\n",
    "        push!(df, (scenario, policy, metric, f(log)))\n",
    "    end\n",
    "end\n",
    "df = unstack(df, :metric, :value);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.scenario .== \"Singapore_HongKong\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
